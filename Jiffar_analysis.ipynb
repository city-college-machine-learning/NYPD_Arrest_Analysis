{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NYPD ARREST DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The NYPD just arrested a person. You are told the crime commited, gender and age of person and location of crime. Can you predict the race of the person with accuracy and precision?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to create a supervised machine learning algorithm to predict the race accurately.\n",
    "\n",
    "First, we will load the data, then clean it, and explore it and along the way get it ready for the classification task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'family': 'serif','color':  'darkred','weight': 'normal','size': 16}\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load in the data\n",
    "data = pd.read_csv('NYPD_Arrest_Data__Year_to_Date_.csv')\n",
    "#Look at five rows\n",
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Look at the columns and rows\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Data Dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#The Data Dictionary for the Columns obtained from the NYPD Website\n",
    "data_dictionary = \"\"\"\n",
    "ARREST_KEY: Randomly generated persistent ID for each arrest\n",
    "\n",
    "ARREST_DATE: Exact date of arrest for the reported event\n",
    "\n",
    "PD_CD: Three digit internal classification code (more granular than\n",
    "Key Code)\n",
    "\n",
    "PD_DESC: Description of internal classification corresponding with PD\n",
    "code (more granular than Offense Description)\n",
    "\n",
    "KY_CD: Three digit internal classification code (more general\n",
    "category than PD code)\n",
    "\n",
    "OFNS_DESC: Description of internal classification corresponding with KY\n",
    "code (more general category than PD description)\n",
    "\n",
    "LAW_CODE: Law code charges corresponding to the NYS Penal Law,\n",
    "VTL and other various local laws\n",
    "\n",
    "LAW_CAT_CD: Level of offense: felony, misdemeanor, violation\n",
    "\n",
    "ARREST_BORO: Borough of arrest. B(Bronx), S(Staten Island), K(Brooklyn),\n",
    "M(Manhattan), Q(Queens)\n",
    "\n",
    "ARREST_PRECINCT: Precinct where the arrest occurred\n",
    "\n",
    "JURISDICTION_CODE: Jurisdiction responsible for arrest. Jurisdiction codes\n",
    "0(Patrol), 1(Transit) and 2(Housing) represent NYPD whilst\n",
    "codes 3 and more represent non NYPD jurisdictions\n",
    "\n",
    "AGE_GROUP: Perpetrator’s age within a category\n",
    "\n",
    "PERP_SEX: Perpetrator’s sex description\n",
    "\n",
    "PERP_RACE: Perpetrator’s race description\n",
    "\n",
    "X_COORD_CD: Midblock X-coordinate for New York State Plane\n",
    "Coordinate System, Long Island Zone, NAD 83, units feet (FIPS 3104)\n",
    "\n",
    "Y_COORD_CD: Midblock Y-coordinate for New York State Plane\n",
    "Coordinate System, Long Island Zone, NAD 83, units feet (FIPS 3104)\n",
    "\n",
    "Latitude: Latitude coordinate for Global Coordinate System, WGS\n",
    "1984, decimal degrees (EPSG 4326)\n",
    "\n",
    "Longitude: Longitude coordinate for Global Coordinate System, WGS\n",
    "1984, decimal degrees (EPSG 4326)\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#change borough columns to make it clear\n",
    "borough= {'K': 'Brooklyn', 'M': 'Manhattan','B':'Bronx','Q':\"Queens\", 'S':'Staten Island'}\n",
    "#change the crime labels to make it clear\n",
    "crimes = {'M': 'Misdemeanor', 'F':'Felony', 'V':'Violation' ,'I':'Infraction'}\n",
    "#change the gender labels\n",
    "gender = {'M': 'Male', 'F':'Female'}\n",
    "#Replace borough label\n",
    "data['ARREST_BORO'] = data['ARREST_BORO'].replace(borough)\n",
    "#Replace Crime label\n",
    "data['LAW_CAT_CD'] = data['LAW_CAT_CD'].replace(crimes)\n",
    "#Replace gender label\n",
    "data['PERP_SEX'] =  data['PERP_SEX'].replace(gender)\n",
    "# Change the column names\n",
    "data.rename(columns={'PD_DESC':'OFFENSE_DESC_1', 'OFNS_DESC':'OFFENSE_DESC_2' ,'LAW_CAT_CD':'LEVEL_OF_OFFENSE','PD_CD':'INTERNAL_CODE_1','KY_CD':'INTERNAL_CODE_2'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Look at the unique values for each column with less than 20 unique values\n",
    "for column in data.columns:\n",
    "    if len(data[column].unique()) <20:\n",
    "        print(column,':',data[column].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above categorical values are found in the data. The LAW_CAT_CD is type of crime indicator (dictionary above) that lists felony, misdemeanor, violation, etc. The others are Borough (ARREST_BORO), age group (AGE_GROUP), gender (PERP_SEX), and race (PERP_RACE)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let me look at columns that have more than 20 unique values next.\n",
    "Because the dataframe is 214617 rows long (as seen in the output from data.info()), I am going to keep any column with unique features that are under 1000 in number. Even though 1000 is a big number, it is much smaller than ~200,000. To be exact, it is half a percent."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Look at the unique values for columns containing greater than 20 values\n",
    "#We don't want TOO MUCH variability because easier to cause overfitting\n",
    "for column in data.columns:\n",
    "    print(column,'unique values:',len(data[column].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.INTERNAL_CODE_2.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Based on the above unique counts, I will select the following columns to drop \n",
    "#because they are not useful features to train a classifier.\n",
    "drop_following = \"\"\"\n",
    "Columns to drop:\n",
    "\n",
    "ARREST_KEY: this is a unique identifier used internally by the NYPD. It serves no purpose here.\n",
    "ARREST_DATE: WE will drop this and bin it into to Month\n",
    "X_COORD_CD: Not using coordinates in logistic regression\n",
    "Y_COORD_CD: Not using coordinates in logistic regression\n",
    "Latitude: Not using coordinates\n",
    "Longitude: Not using coordinates\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Drop the columns that wont provide informational value\n",
    "data.drop(['ARREST_KEY', 'X_COORD_CD','Y_COORD_CD', 'Latitude','Longitude','ARREST_DATE'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#How many empty values are there in each column?\n",
    "data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Because there are not that many nulls, won't worry about them, just going to drop them\n",
    "data.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data['ARREST_DATE'] = pd.to_datetime(data['ARREST_DATE'], format = \"%m/%d/%Y\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create a catagoric column for month\n",
    "#Use a function to convert the date into a month category. \n",
    "# Then use one-hot encoding to convert the months into twelve variables "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that the data is ready, we will proceed with exploring the columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Borough"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Number of arrests by Borough\n",
    "arrest_by_boro = data.groupby('ARREST_BORO').ARREST_BORO.count()\n",
    "arrest_by_boro = pd.DataFrame(arrest_by_boro.sort_values(ascending = False))\n",
    "#Plot race of arrested\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(num=None, figsize=(15, 7))\n",
    "ax = plt.axes()\n",
    "ax = data.ARREST_BORO.value_counts(sort=True).plot(kind='bar')\n",
    "ax.set_title('Numbers Arrested by Borough',fontsize=18)\n",
    "ax.set_xlabel(\"Borough\",fontsize=18)\n",
    "ax.set_ylabel(\"Number of Arrested\",fontsize=18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Looking at the types of arrests by Borough\n",
    "fig = plt.figure(num=None, figsize=(20, 7))\n",
    "ax = plt.axes()\n",
    "ax = data.groupby('LEVEL_OF_OFFENSE')['ARREST_BORO'].value_counts(sort=True).plot(kind='bar',)\n",
    "ax.set_title('Numbers Arrested in Borough for Type of Crime',fontsize=18,fontdict=font)\n",
    "ax.set_xlabel(\"Type of Crime and Borough\",fontsize=18,fontdict=font)\n",
    "ax.set_ylabel(\"Number of Arrested\",fontsize=18,fontdict=font)\n",
    "ax.tick_params(labelsize=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Brooklyn has the most felonies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Arrests by Boro Precinct\n",
    "font = {'family': 'serif','color':  'darkred','weight': 'normal','size': 16}\n",
    "fig = plt.figure(num=None, figsize=(20, 7))\n",
    "ax = plt.axes()\n",
    "ax = data.groupby('ARREST_BORO').ARREST_PRECINCT.value_counts(sort=True).plot(kind='bar')\n",
    "ax.set_title('Numbers Arrested in Borough and Precinct',fontsize=18,fontdict=font)\n",
    "ax.set_xlabel(\"Borough and Police Precinct\",fontsize=18,fontdict=font)\n",
    "ax.set_ylabel(\"Number of Arrested\",fontdict=font)\n",
    "ax.tick_params(labelsize=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Age"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see below a majority of arrested persons are between 25 and 44."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Age Group of Arrested\n",
    "counts = data.AGE_GROUP.value_counts()\n",
    "percent = data.AGE_GROUP.value_counts(normalize = True).mul(100).round(2).astype(str) + '%'\n",
    "pd.DataFrame({'Counts': counts, 'Percent': percent})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes()\n",
    "ax = data.AGE_GROUP.value_counts(sort=True).plot(kind='bar')\n",
    "ax.set_title('Numbers Arrested in Age Group',fontsize=18,fontdict=font)\n",
    "ax.set_xlabel(\"Age Group\",fontsize=18,fontdict=font)\n",
    "ax.set_ylabel(\"Number of Arrested\",fontsize=18,fontdict=font)\n",
    "ax.tick_params(labelsize=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Race"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Race is an important feature for this project. One of the main attempts of our classification tasks is to see if we can predict race from the other arrest features. Doing this will allow us to know if there are distinct characteristics to a crime that may indicate a person's race."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Race of Arrested\n",
    "counts = data.PERP_RACE.value_counts()\n",
    "percent = data.PERP_RACE.value_counts(normalize = True).mul(100).round(2).astype(str) + '%'\n",
    "pd.DataFrame({'Counts': counts, 'Percent': percent})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot race of arrested\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(num=None, figsize=(15, 7))\n",
    "ax = plt.axes()\n",
    "ax = data.PERP_RACE.value_counts(sort =True).plot(kind='bar')\n",
    "ax.set_title('Numbers Arrested by Race',fontsize=18)\n",
    "ax.set_xlabel(\"Race\",fontsize=18)\n",
    "ax.set_ylabel(\"Number of Arrested\",fontsize=18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Black persons are just under 50% of those arrested. If we add Black Hispanic, then black people make up a majority of arrests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Race and Age"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Races of the Arrested by Age Group\n",
    "counts = data.groupby('AGE_GROUP').PERP_RACE.value_counts(sort=True)\n",
    "# pd.DataFrame({'Counts': counts})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most of those arrested are between 25 to 44. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(num=None, figsize=(17, 7))\n",
    "ax = plt.axes()\n",
    "ax = data.groupby('AGE_GROUP').PERP_RACE.value_counts(sort=True).plot(kind='bar')\n",
    "ax.set_title('Numbers Arrested in Age Group and Race',fontsize=18,fontdict=font)\n",
    "ax.set_xlabel(\"Age Group and Race\",fontsize=18,fontdict=font)\n",
    "ax.set_ylabel(\"Number of Arrested\",fontsize=18,fontdict=font)\n",
    "ax.tick_params(labelsize=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks from the shape of the above graphs that every race has the same pattern of arrests by age group. So every race behaves the same across age."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gender"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we see that 81.64% of those arrested are men"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Male vs Female\n",
    "counts = data.PERP_SEX.value_counts()\n",
    "percent = data.PERP_SEX.value_counts(normalize = True).mul(100).round(2).astype(str) + '%'\n",
    "pd.DataFrame({'Counts': counts, 'Percent':percent})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gender and Race"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the relationship between gender and race?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Arrests by Gender and Race\n",
    "font = {'family': 'serif','color':  'darkred','weight': 'normal','size': 16}\n",
    "fig = plt.figure(num=None, figsize=(20, 7))\n",
    "ax = plt.axes()\n",
    "ax = data.groupby('PERP_SEX').PERP_RACE.value_counts(sort=True).plot(kind='bar')\n",
    "ax.set_title('Number of Arrested, Gender and Race',fontsize=18,fontdict=font)\n",
    "ax.set_xlabel(\"Gender and Race\",fontsize=18,fontdict=font)\n",
    "ax.set_ylabel(\"Number of Arrested\",fontdict=font)\n",
    "ax.tick_params(labelsize=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Black males make up the largest portion of those arrested. The number of arrested males of each race is more than its female counterparts: Males are more criminal in general."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Look at the data columns again\n",
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Look at the data types again\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Turn everything into an object because the numerical values don't have numerical meaning and won't be used (one-hot-encoder will be used next)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Turn everything into an object because the numerical values don't have numerical meaning and won't be used (one-hot-encoder will be used next)\n",
    "data = data.astype('object')\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One-hot-encoded data is created because the features are categorical entirely."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create one hot encoded data\n",
    "target_removed = data.loc[:, data.columns != 'PERP_RACE']\n",
    "X = pd.get_dummies(target_removed)\n",
    "target = data.loc[:,'PERP_RACE']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Look at the one hot encoded table\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Look at the table dimensions\n",
    "X.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Visually inspect the new one-hot encoded columns\n",
    "X.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Test Validaiton Split for Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train Test Split the data\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split( X, target, test_size=0.2, random_state=42)\n",
    "#Keep testing set for final testing, so make validation set here\n",
    "X_train, X_val, y_train, y_val = train_test_split( X_train_all, y_train_all, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regerssion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Fit logistic Regression\n",
    "lr = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "lr.fit(X_train, y_train)\n",
    "#Predict on training set\n",
    "lr_y_pred = lr.predict(X_train)\n",
    "print('Logistic Training accuracy: ', accuracy_score(y_train, lr_y_pred))\n",
    "#Print training classification report\n",
    "print(classification_report(y_train, lr_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predict validation accuracy\n",
    "lr_y_pred_val = lr.predict(X_val)\n",
    "print('Logistic Validation accuracy: ', accuracy_score(y_val, lr_y_pred_val))\n",
    "\n",
    "#Print validation classification report\n",
    "print(classification_report(y_val, lr_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNeighbours Classifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Creat knn object and fit data\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #predict the training accuracy\n",
    "# knn_y_pred = knn.predict(X_train)\n",
    "# print('knn training accuracy: ', accuracy_score(y_train, y_pred_knn))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Print training classification report\n",
    "# print(classification_report(y_train, knn_y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Predict validation accuracy\n",
    "# lr_y_pred_val = lr.predict(X_val)\n",
    "# print('KNN Validation accuracy: ', accuracy_score(y_val, lr_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Print validation classification report\n",
    "# print(classification_report(y_val, lr_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Creat support vector object and fit data\n",
    "svc = LinearSVC(C=10)\n",
    "svc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predict training accuracy \n",
    "svc_y_pred = svc.predict(X_train)\n",
    "print('svc training accuracy: ', accuracy_score(y_train, svc_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print training classification report\n",
    "print(classification_report(y_train, svc_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predict validation accuracy\n",
    "svc_y_pred_val = lr.predict(X_val)\n",
    "print('SVC Validation accuracy: ', accuracy_score(y_val, svc_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print validation classification report\n",
    "print(classification_report(y_val, svc_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Creat Decision Tree classifier and fit data\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predict training accuracy \n",
    "decision_tree_y_pred = svc.predict(X_train)\n",
    "print('Decision Tree training accuracy: ', accuracy_score(y_train, decision_tree_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print training classification report\n",
    "print(classification_report(y_train, decision_tree_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predict validation accuracy\n",
    "decision_tree_y_pred_val = decision_tree.predict(X_val)\n",
    "print('Decision Tree validation accuracy: ', accuracy_score(y_val, decision_tree_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print validation classification report\n",
    "print(classification_report(y_val, decision_tree_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Creat Decision Tree classifier and fit data\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predict training accuracy \n",
    "rforest_y_pred = svc.predict(X_train)\n",
    "print('Random Forest training accuracy: ', accuracy_score(y_train, rforest_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print training classification report\n",
    "print(classification_report(y_train, rforest_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predict validation accuracy\n",
    "rforest_y_pred_val = lr.predict(X_val)\n",
    "print('Random Forest Validation accuracy: ', accuracy_score(y_val, rforest_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print validation classification report\n",
    "print(classification_report(y_val, rforest_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Principal Component Analysis (PCA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Use PCA to look at the explained variance by column in order to reduce the dimension for arrest features\n",
    "pca = PCA(n_components=150)\n",
    "pca.fit(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calculate variance ratios\n",
    "variance = pca.explained_variance_ratio_ \n",
    "var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3)*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot the PCA info\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "# plt.ylim(30,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "plt.plot(var)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see from using a 150 components PCA that the explained variance starts to plateau after 20 components; and that it does not improve much after 100 compoents (at which point percentage explained is 90%). At this point, since our classifiers are not performing very well, reducing any number of components will likely make them perform less. But,  even if they perfrom slightly less, it is worth reducing th enumber of dimensions from the current column numbers 1892 down to about 100."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Use PCA to look at the explained variance by column\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_train)\n",
    "pca_X_train = pca.transform(X_train)\n",
    "pca_X_val = pca.transform(X_val)\n",
    "\n",
    "#Fit logistic Regression\n",
    "lr = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "lr.fit(pca_X_train, y_train)\n",
    "#Predict on training set\n",
    "lr_y_pred = lr.predict(pca_X_train)\n",
    "print('Logistic Training accuracy: ', accuracy_score(y_train, lr_y_pred))\n",
    "\n",
    "#Print training classification report\n",
    "print(classification_report(y_train, lr_y_pred))\n",
    "\n",
    "#Predict validation accuracy\n",
    "lr_y_pred_val = lr.predict(pca_X_val)\n",
    "print('Logistic Validation accuracy: ', accuracy_score(y_val, lr_y_pred_val))\n",
    "\n",
    "#Print validation classification report\n",
    "print(classification_report(y_val, lr_y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After PCA, the accuracy did not increase much. But recall did improve slightly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}